---
title: "R Notebook"
---

# Libraries

```{r}

library(tidyverse)
library(rcrossref)

```

# Retrieve preprint metadata via bioRxiv API

```{r}

# See https://api.biorxiv.org for details
# Note that the API allows querying of both bioRxiv and medRxiv via the 
# 'server' parameter (although this is not documented)

max_results_per_page <- 100
base_url <- "https://api.biorxiv.org/details/"

getPreprintData <- function(server) {
  
  # Make initial request
  url <- paste0(base_url, server, "/2020-01-01/", Sys.Date(), "/", 0)
  request <- httr::GET(url = url)
  content <- httr::content(request, as = "parsed")
  
  # Determine total number of results and required iterations for paging
  total_results <- content$messages[[1]]$total
  iterations <- ceiling(total_results / max_results_per_page) - 1
  
  data <- content$collection

  for (i in 1:iterations) {
    cursor <- i * max_results_per_page
    url <- paste0(base_url, server, "/2020-01-01/", Sys.Date(), "/", cursor)
    request <- httr::GET(url)
    content <- httr::content(request, as = "parsed")
    data <- c(data, content$collection)
    Sys.sleep(1) # don't hit the API too hard
  }
  return(data)
}

preprint_data <- purrr::map(c("biorxiv", "medrxiv"), getPreprintData)

parsePreprintData <- function(item) {
  tibble(
    source = item$server,
    doi = item$doi,
    title = item$title,
    authors = item$authors,
    author_corresponding = item$author_corresponding, 
    author_corresponding_institution = item$author_corresponding_institution,
    posted_date = item$date,
    version = item$version,
    type = item$type,
    category = item$category,
    abstract = item$abstract,
    is_published = item$published != "NA",
    published_doi = if(item$published == "NA") NA_character_ else item$published
  )
}

# Build a search string containing terms related to COVID-19
search_string <- "coronavirus|covid-19|sars-cov|ncov-2019|2019-ncov|hcov-19|human_coronavirus 2019|sars-2|wuhan seafood market pneumonia virus|ncip|pars"

# Parse data to dataframe
preprints <- map_df(preprint_data, ~ map_df(.x, parsePreprintData)) %>%
  filter(version == 1) %>%
  # clean up DOIs for later matching
  mutate(
    doi = str_trim(str_to_lower(doi)),
    published_doi = str_trim(str_to_lower(published_doi)),
    covid_preprint = case_when(
      str_detect(title, regex(search_string, ignore_case = TRUE)) ~ T, 
      str_detect(abstract, regex(search_string, ignore_case = TRUE)) ~ T,
      T ~ F)
    ) %>%
  # some duplicates are included - filter them out
  distinct()

```

# Retrieve published article metadata via Crossref

```{r}

published_dois <- preprints %>% filter(is_published == T) %>% pull(published_doi)

published_articles_data <- rcrossref::cr_works_(published_dois, parse = T)

parsePublishedArticleData <- function(item) {
  tibble(
    published_doi = item$message$DOI,
    published_title = item$message$title[[1]],
    published_date = lubridate::date(item$message$created$`date-time`),
    published_abstract = if(length(item$message$abstract)) item$message$abstract else NA_character_,
    published_journal = item$message$`container-title`[[1]],
    published_publisher = item$message$publisher
  )
}

published_articles <- map_df(published_articles_data, parsePublishedArticleData) %>%
  mutate(published_doi = str_trim(str_to_lower(published_doi)))

```

# Disambiguate author affiliations (via ROR affiliation matching)

```{r}

# See https://github.com/ror-community/ror-api
# The full string of the institution name is passed to the ROR institution
# matching API. The API returns a list of possible matches, including a 
# match score (between zero and one, one being a perfect match), and the match
# type (e.g. matching on common terms in institution names, or on....). 
# The first institution returned (which always has the highest score) is retained.

getAuthorAffiliations <- function(doi, institution) {
  
  base_url <- "https://api.ror.org/organizations?affiliation="
  encoded_institution <- URLencode(institution)
  url <- paste0(base_url, encoded_institution)
  request <- httr::GET(url)
  content <- httr::content(request, as = "parsed")
  if(length(content$items)) {
    data <- content$items
    tibble(
      doi = doi,
      institution_match_score = data[[1]]$score,
      institution_match_type = data[[1]]$matching_type,
      institution_match_name = data[[1]]$organization$name,
      institution_match_country_name = data[[1]]$organization$country$country_name,
      institution_match_country_code = data[[1]]$organization$country$country_code
    )
  }
}

affiliations <- map2_df(preprints$doi,
                        preprints$author_corresponding_institution, 
                        getAuthorAffiliations)

```

# Merge preprint and published articles dataset

```{r}

final <- preprints %>%
  left_join(published_articles, by = "published_doi") %>%
  left_join(affiliations, by = "doi")

```
